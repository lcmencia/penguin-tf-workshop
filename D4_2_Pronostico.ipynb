{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8kEs7ZfgkxSH"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/torresmateo/penguin-tf-workshop/blob/master/D4_2_Pronostico.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Predicción del clima\n",
    "\n",
    "Este notebook introduce la predicción en series temporales. Las aplicaciones de este tipo de predicción son muy diversas, como detección de arritmias cardíacas hasta predecir fluctuaciones de precios en la bolsa.\n",
    "\n",
    "Primero que nada, importamos las bibliotecas necesarias. En esta ocasión, preste mucha atención, pues usaremos más bibliotecas que en ejemplos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfGddyEOkQ8K"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# importamos Pandas, que nos permitirá ver mejor los datos\n",
    "import pandas as pd\n",
    "\n",
    "# configuramos las figuras de matplotlib\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsVEXkKOlkY9"
   },
   "source": [
    "# Importar el dataset\n",
    "\n",
    "El [*dataset*](https://www.bgc-jena.mpg.de/wetter/) que usamos en este caso es del clima y fue recopilado por el [Max Planck Institute for Biogeochemistry](https://www.bgc-jena.mpg.de/index.php/Main/HomePage). Contiene 14 variables diferentes como temperatura, presión atmosférica, humedad, etc. \n",
    "\n",
    "Fueron recolectados cada 10 minutos desde el 2003. Nosotros usaremos datos desde el 2009 hasta el 2016 por eficiencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JhWQuqAlkIY"
   },
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lyNh77xnalO"
   },
   "source": [
    "con el dataset ya en el disco duro, podemos importarlo. Para ello, usamos Pandas, que parsea y convenientemente nos deja explorar el dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zDRMHUgRnlur",
    "outputId": "c832366b-ef4e-458e-bf03-7165354d055d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zxdicVWnvHk"
   },
   "source": [
    "Como podemos observar, tenemos 14 variables numéricas, que van cambiando con el tiempo. Esto nos permitirá modelar la evolución del clima. \n",
    "\n",
    "Veamos el tamaño de nuestro dataset. Podemos además usar funcionalidades de pandas para tener una idea de la distribución de cada una de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "s4wW90Q9piPW",
    "outputId": "c77e70d8-2150-4e9f-8a3a-c9103c2292a7"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImKKDEZPqBNv"
   },
   "source": [
    "aqui podemos ver con claridad los diferentes rangos y distribuciones de cada una de las variables. Es siempre importante familiarizarse con los datos antes de saltar a probar modelos de predicción. Algunas preguntas útiles en este punto son:\n",
    "\n",
    "* ¿Tiene sentido el rango de esta variable?\n",
    "* ¿Es este el mejor tipo de dato para representar este valor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2stTmFtpyxA"
   },
   "source": [
    "# Preparar un *dataset* univariable\n",
    "\n",
    "Un aspecto interesante de las series temporales es la multitud de formas en que podemos desear predecir. En cada caso, los ejemplos de entrenamiento tienen que ser cuidadosamente preparados para maximizar el éxito de la tarea de predicción. \n",
    "\n",
    "Supongamos que nuestra tarea es predecir la temperatura de las siguientes 6 horas. Para ello, elegimos considerar los datos de los 5 días previos. \n",
    "\n",
    "Veamos como podemos construir un dataset para esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vZQ7pzArFCl"
   },
   "outputs": [],
   "source": [
    "def construir_dataset_univariable(dataset, inicio, fin, ancho_ventana, offset_prediccion):\n",
    "    # definimos las variables donde se guardará el dataset\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # el inicio y el fin determinan los límites en el tiempo que vamos a analizar\n",
    "    # como vamos a ir mirando \"hacia atras\" sumamos el tamaño de la ventana previa\n",
    "    # al primer punto temporal, de tal manera a movernos correctamente al \n",
    "    # extraer los ejemplos y labels\n",
    "    inicio = inicio + ancho_ventana \n",
    "    if fin is None:\n",
    "        fin = len(dataset) - offset_prediccion\n",
    "\n",
    "    # recorremos la serie temporal para ir extrayendo ejemplos\n",
    "    for i in range(inicio, fin):\n",
    "        # definimos los indices de la ventana previa (datos que usaremos para predecir el futuro inmediato)\n",
    "        ventana = range(i-ancho_ventana, i)\n",
    "\n",
    "        # recolectamos la ventana previa a lo que queremos predecir\n",
    "        # nos aseguramos que nuestro dato tenga la dimensionalidad correcta (univariable)\n",
    "        data.append(np.reshape(dataset[ventana], (ancho_ventana, 1)))\n",
    "\n",
    "        # recolectamos la \"respuesta\" (la ventana de datos que queremos predecir)\n",
    "        labels.append(dataset[i+offset_prediccion])\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9eLrTr6tumH"
   },
   "source": [
    "En estas predicciones, usaremos los primeros 300000 ejemplos como *training set*, y el resto como *testing set*. Al usar series temporales se debe prestar mucha atención al hacer la partición del dataset, si queremos predecir el futuro, no es bueno \"conocer el futuro\" (usar los datos más recientes para el *training*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahhQvImluYLF"
   },
   "outputs": [],
   "source": [
    "particion = 300000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2k-fo5cugGU"
   },
   "source": [
    "# Predicción de temperatura\n",
    "\n",
    "con nuestra función para construir ejemplos a partir del dataset, podemos empezar a hacer un pronóstico de temperatura. Primeramente, vamos a aislar los datos que nos interesan en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "IDn1ru1Mu5Y7",
    "outputId": "4cba946d-dd24-497b-ed20-47ce9aebd074"
   },
   "outputs": [],
   "source": [
    "# extraemos los datos de temperatura (en grados centígrados)\n",
    "temp_data = df['T (degC)']\n",
    "# hacemos que el índice de nuestro DataFrame de pandas sea la fecha del registro de temperatura\n",
    "temp_data.index = df['Date Time']\n",
    "# visualizamos nuestro dataset filtrado\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OA0Ty6jNvYP4"
   },
   "source": [
    "y observemos como se ve la serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "LXNrtTebvcfl",
    "outputId": "3d188cc3-f8a4-4efa-c876-2cdfe3cf6485"
   },
   "outputs": [],
   "source": [
    "temp_data.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSxNeDrQxP43"
   },
   "source": [
    "Como queremos lidiar solamente con un array de numpy y no un DataFrame de pandas, extraemos todos los valores, pues ya estan correctamente ordenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPJfVyIVxYqr"
   },
   "outputs": [],
   "source": [
    "temp_data = temp_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Od6E5Osv1bZ"
   },
   "source": [
    "como siempre, es conveniente que normalicemos nuestro *dataset*. Hay muchas formas de normalizar. Nosotros vamos a usar el [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de la biblioteca scikit-learn. Esta normalización remueve la media y divide entre la desviación estándar.\n",
    "\n",
    "En este caso, es importante que nuestro *dataset* tenga dimensionalidad `(n_ejemplos, n_variables)`, pues es requerido por el `StandardScaler`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iqnSbwf6yCc8",
    "outputId": "af4f6ba7-0db3-427b-fc04-f28150e0d60d"
   },
   "outputs": [],
   "source": [
    "print(f'dimensionalidad inicial: {temp_data.shape}')\n",
    "temp_data = temp_data.reshape(temp_data.shape[0], 1)\n",
    "print(f'dimensionalidad final: {temp_data.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avRKOMyUyOjs"
   },
   "source": [
    "**Note:** Esto es un comportamiento específico de numpy, y un requerimiento específico del `StandardScaler`.\n",
    "\n",
    "Es importante notar que el escalador solo debe ajustarse al *training set*, pero el *testing set* debe ser normalizado igualmente. Es decir, A ambos sets se resta el promedio y se divide la desviación estándar del *training set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSDrANuWwjW3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# por ahora solo extraemos el training set, que se usa para calcular los parámetros para normalizar\n",
    "training_data = temp_data[:particion] \n",
    "scaler.fit(training_data)\n",
    "\n",
    "# normalizamos todo el dataset\n",
    "temp_data = scaler.transform(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWAU6ZSiyb6E"
   },
   "source": [
    "exploremos de nuevo nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "JJS74HYMxI5V",
    "outputId": "99d37331-1900-491f-fd20-3c06b2c756ad"
   },
   "outputs": [],
   "source": [
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "p6gGnUDuygN7",
    "outputId": "332c4924-efd4-42a2-c51d-5d591aaf3416"
   },
   "outputs": [],
   "source": [
    "plt.plot(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sBSx0wYysXZ"
   },
   "source": [
    "podemos ver que la figura cambio muy poco, en particular, estamos en un rango mucho más chico. También se puede hacer una normalización entre 0 y 1 usando el `MinMaxScaler`.\n",
    "\n",
    "Creemos ahora los ejemplos de *training* y *testing* usando la función que definimos más arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_A3pkioM0Trm"
   },
   "outputs": [],
   "source": [
    "ancho_ventana = 20\n",
    "prediccion = 0\n",
    "\n",
    "# extraemos los ejemplos de training\n",
    "x_train, y_train = construir_dataset_univariable(temp_data, 0, particion, ancho_ventana, prediccion)\n",
    "\n",
    "# extraemos los ejemplos de testing\n",
    "x_test, y_test = construir_dataset_univariable(temp_data, particion, None, ancho_ventana, prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emMf6Ow30D99"
   },
   "source": [
    "exploremos un ejemplo de nuestro *training set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "epHuu3sc1jff",
    "outputId": "382bd22b-83d1-4fb0-a574-aee52297d6c1"
   },
   "outputs": [],
   "source": [
    "print('historia de temperatura')\n",
    "print(x_train[0])\n",
    "print('temperatura a predecir')\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euhFboPv12iK"
   },
   "source": [
    "podemos visualizar mejor el ejemplo si lo dibujamos como serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHYwWN0J1-VK"
   },
   "outputs": [],
   "source": [
    "def ver_ejemplo(ejemplo, delta, titulos):\n",
    "    rotulos = ['Historia', 'Futuro verdadero'] + titulos[1:]\n",
    "    marker = ['.-', 'rx', 'go', 'mD', 'c<']\n",
    "    tiempos = list(range(-ejemplo[0].shape[0], 0))\n",
    "    if delta:\n",
    "        futuro = delta\n",
    "    else:\n",
    "        futuro = 0\n",
    "    \n",
    "    plt.title(titulos[0])\n",
    "    for i, x in enumerate(ejemplo):\n",
    "        if i:  # futuro verdadero o predicción\n",
    "            plt.plot(futuro, ejemplo[i], marker[i], markersize=10, label=rotulos[i])\n",
    "        else:  # historia\n",
    "            plt.plot(tiempos, ejemplo[i], marker[i], label=rotulos[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([tiempos[0], (futuro+5)*2])\n",
    "    plt.xlabel('Tiempo')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3pSLAF13k4L"
   },
   "source": [
    "vemos el primer ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "GTBXVMq03mQc",
    "outputId": "8d93be60-6f61-4789-d972-9d6275a886d9"
   },
   "outputs": [],
   "source": [
    "ver_ejemplo([x_train[0], y_train[0]], 0, ['Ejemplo 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJMq6rP439Se"
   },
   "source": [
    "# Modelo simple (baseline)\n",
    "\n",
    "Para poder comparar nuestro modelo con un modelo simple que puede servirnos de base, definimos una función que predice el futuro haciendo un promedio de los valores históricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD4srVuw4NeG"
   },
   "outputs": [],
   "source": [
    "def modelo_promedio(historia):\n",
    "    return np.mean(historia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6QA5vAW4T0z"
   },
   "source": [
    "veamos que tan bien podemos predecir usando este simple modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "1iGxo3184Y6z",
    "outputId": "a3f48fcb-1d7e-428a-a711-41912e32ccba"
   },
   "outputs": [],
   "source": [
    "ver_ejemplo([x_train[0], y_train[0], modelo_promedio(x_train[0])], 0, ['Ejemplo 0', 'Promedio histórico'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96WkJxHw4otl"
   },
   "source": [
    "# Red neuronal recurrente\n",
    "\n",
    "Vamos a ver si podemos superar al valor histórico promedio usando una red neuronal recurrente.\n",
    "\n",
    "En este caso, introducimos un tipo de *layer* recurrente: Long Short Term Memory ([LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM))\n",
    "\n",
    "Primero que nada, veamos como podemos preparar un dataset de tensorflow que separe nuestros ejemplos en batches. Hay 3 cosas importantes que introducimos en este caso:\n",
    "\n",
    "* **cache:** optimiza el acceso de tensorflow a los ejemplos en memoria\n",
    "* **shuffle:** randomiza el orden en que los ejemplos se incluyen en el dataset.\n",
    "* **batch:** determina cuantos ejemplos del dataset se usan antes de actualizar los pesos de la red neuronal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JREwVGR8_Oyr"
   },
   "outputs": [],
   "source": [
    "batch = 256\n",
    "buffer = 10000\n",
    "\n",
    "# creamos el training dataset\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train = train.cache().shuffle(buffer).batch(batch).repeat()\n",
    "\n",
    "# creamos el testing dataset\n",
    "test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test = test.batch(batch).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYapVCSfAKyl"
   },
   "source": [
    "Si desea entender como funcionan los comandos `batch` y `repeat` le recomiendo leer [esta respuesta en stackoverflow](https://stackoverflow.com/a/53517848/943138) (en inglés).\n",
    "\n",
    "# Crear la red neuronal\n",
    "\n",
    "vamos a crear una red neuronal recurrente relativamente sencilla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a77SDTFFAcam"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.LSTM(8, input_shape=x_train.shape[-2:]),\n",
    "                                    tf.keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrPt6LmABu3u"
   },
   "source": [
    "entrenar la red neuronal.\n",
    "\n",
    "Introducimos nuevos parámetros al momento de entrenar.\n",
    "* `stops_per_epoch`: va a correr por 200 pasos (batches), y no por todo el dataset en cada *epoch*\n",
    "* `validation_steps`: la cantidad de batches del *testing set* que se usan para medir la función de costo de evaluación en cada *epoch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "NUeZ1eoCCfR8",
    "outputId": "67c73bc4-85d1-4e5a-f033-7749e1097feb"
   },
   "outputs": [],
   "source": [
    "model.fit(train, epochs=10, steps_per_epoch=200, validation_data=test, validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qzbl11__DbEy"
   },
   "source": [
    "veamos algunas predicciones comparando con el modelo que predice el promedio histórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j1y8ZDIbEIi8",
    "outputId": "4022eceb-f92c-4e23-e21c-477c77371fae"
   },
   "outputs": [],
   "source": [
    "x.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rqq_YUaNDh7T",
    "outputId": "6fbf7d11-6fa7-4a2f-8062-d0da57bad101"
   },
   "outputs": [],
   "source": [
    "for x,y in test.take(4):\n",
    "    ver_ejemplo([x[0].numpy() ,y[0].numpy(), model.predict(x)[0], modelo_promedio(x)], 0, \n",
    "                ['Comparación de modelos', 'shallow LSTM', 'Promedio histórico'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkMxU-S3klyQ"
   },
   "source": [
    "# Créditos\n",
    "\n",
    "Este notebook traduce y adapta el código y explicaciones del [Tutorial de Tensorflow](https://www.tensorflow.org/tutorials/structured_data/time_series) en series temporales."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "D4_2_Pronostico.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
